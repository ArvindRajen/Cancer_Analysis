{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "prostate-cancer-predictions-with-ml-and-dl-methods.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArvindRajen/Cancer_Analysis/blob/main/prostate_cancer_predictions_with_ml_and_dl_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a679995615a32bdd09f5213d70b25820aff0f2e5",
        "id": "cOxS9syq3x1k"
      },
      "source": [
        "#**INTRODUCTION**\n",
        "\n",
        "I'll train Prostate Cancer data with some machine learning and deep learning methods. \n",
        "\n",
        "* EDA (Exploratory Data Analysis)\n",
        "* Data Preprocessing (Scaling, Reshaping)\n",
        "* Test-Train Dataset Split\n",
        "* Logistic Regression Classification\n",
        "* KNN Classification\n",
        "* Support Vector Machine (SVM) Classification\n",
        "* Naive Bayes Classification\n",
        "* Desicion Tree Classification\n",
        "* Random Forest Classification\n",
        "* Artificial Neural Network\n",
        "* Recurrent Neural Network\n",
        "* Compare all of these Classification Models\n",
        "* Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "40Rb7Lma3x1m"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "GtFZz-sy3x1w"
      },
      "source": [
        "Cancer = pd.read_csv(\"/content/Prostate_Cancer.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "5e5558aa7e42975c3cb3bb5be8fcdf63d2b8d75e",
        "id": "aFX60X6a3x14",
        "outputId": "4d1e911f-3c1d-48ca-cb0f-c349d42578bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Cancer.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 100 non-null    int64  \n",
            " 1   diagnosis_result   100 non-null    object \n",
            " 2   radius             100 non-null    int64  \n",
            " 3   texture            100 non-null    int64  \n",
            " 4   perimeter          100 non-null    int64  \n",
            " 5   area               100 non-null    int64  \n",
            " 6   smoothness         100 non-null    float64\n",
            " 7   compactness        100 non-null    float64\n",
            " 8   symmetry           100 non-null    float64\n",
            " 9   fractal_dimension  100 non-null    float64\n",
            "dtypes: float64(4), int64(5), object(1)\n",
            "memory usage: 7.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "73f8fc7a937835b320251278256f0d26d79706b2",
        "id": "hmgSu5B83x2A",
        "outputId": "043e194e-6120-4909-9d5f-56b494ab1d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "Cancer.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis_result</th>\n",
              "      <th>radius</th>\n",
              "      <th>texture</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>area</th>\n",
              "      <th>smoothness</th>\n",
              "      <th>compactness</th>\n",
              "      <th>symmetry</th>\n",
              "      <th>fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>151</td>\n",
              "      <td>954</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.278</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>133</td>\n",
              "      <td>1326</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>M</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>130</td>\n",
              "      <td>1203</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.207</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>78</td>\n",
              "      <td>386</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>M</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>135</td>\n",
              "      <td>1297</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>B</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>83</td>\n",
              "      <td>477</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.209</td>\n",
              "      <td>0.076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>M</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>1040</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.109</td>\n",
              "      <td>0.179</td>\n",
              "      <td>0.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>M</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>90</td>\n",
              "      <td>578</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>M</td>\n",
              "      <td>19</td>\n",
              "      <td>24</td>\n",
              "      <td>88</td>\n",
              "      <td>520</td>\n",
              "      <td>0.127</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>84</td>\n",
              "      <td>476</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id diagnosis_result  radius  ...  compactness  symmetry  fractal_dimension\n",
              "0   1                M      23  ...        0.278     0.242              0.079\n",
              "1   2                B       9  ...        0.079     0.181              0.057\n",
              "2   3                M      21  ...        0.160     0.207              0.060\n",
              "3   4                M      14  ...        0.284     0.260              0.097\n",
              "4   5                M       9  ...        0.133     0.181              0.059\n",
              "5   6                B      25  ...        0.170     0.209              0.076\n",
              "6   7                M      16  ...        0.109     0.179              0.057\n",
              "7   8                M      15  ...        0.165     0.220              0.075\n",
              "8   9                M      19  ...        0.193     0.235              0.074\n",
              "9  10                M      25  ...        0.240     0.203              0.082\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7f605aa194d543d468d79491735e5f66581839fd",
        "id": "eVyIdna43x2F",
        "outputId": "178ad9bf-3896-4434-8d35-4d5d3ef17e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "Cancer.tail()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis_result</th>\n",
              "      <th>radius</th>\n",
              "      <th>texture</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>area</th>\n",
              "      <th>smoothness</th>\n",
              "      <th>compactness</th>\n",
              "      <th>symmetry</th>\n",
              "      <th>fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>M</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>132</td>\n",
              "      <td>1264</td>\n",
              "      <td>0.091</td>\n",
              "      <td>0.131</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>B</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>78</td>\n",
              "      <td>451</td>\n",
              "      <td>0.105</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98</td>\n",
              "      <td>B</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>62</td>\n",
              "      <td>295</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99</td>\n",
              "      <td>B</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>74</td>\n",
              "      <td>413</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.162</td>\n",
              "      <td>0.066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "      <td>M</td>\n",
              "      <td>16</td>\n",
              "      <td>27</td>\n",
              "      <td>94</td>\n",
              "      <td>643</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.114</td>\n",
              "      <td>0.188</td>\n",
              "      <td>0.064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id diagnosis_result  radius  ...  compactness  symmetry  fractal_dimension\n",
              "95   96                M      23  ...        0.131     0.210              0.056\n",
              "96   97                B      22  ...        0.071     0.190              0.066\n",
              "97   98                B      19  ...        0.053     0.135              0.069\n",
              "98   99                B      21  ...        0.075     0.162              0.066\n",
              "99  100                M      16  ...        0.114     0.188              0.064\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0dea2bf6bf39c45d21f4528fb0981c579899a63d",
        "id": "f3L5ddwZ3x2K",
        "outputId": "58118c6d-4e29-475f-8e9b-09a0620846a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "Cancer.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius</th>\n",
              "      <th>texture</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>area</th>\n",
              "      <th>smoothness</th>\n",
              "      <th>compactness</th>\n",
              "      <th>symmetry</th>\n",
              "      <th>fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>50.500000</td>\n",
              "      <td>16.850000</td>\n",
              "      <td>18.230000</td>\n",
              "      <td>96.780000</td>\n",
              "      <td>702.880000</td>\n",
              "      <td>0.102730</td>\n",
              "      <td>0.126700</td>\n",
              "      <td>0.193170</td>\n",
              "      <td>0.064690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>29.011492</td>\n",
              "      <td>4.879094</td>\n",
              "      <td>5.192954</td>\n",
              "      <td>23.676089</td>\n",
              "      <td>319.710895</td>\n",
              "      <td>0.014642</td>\n",
              "      <td>0.061144</td>\n",
              "      <td>0.030785</td>\n",
              "      <td>0.008151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>0.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>25.750000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>82.500000</td>\n",
              "      <td>476.750000</td>\n",
              "      <td>0.093500</td>\n",
              "      <td>0.080500</td>\n",
              "      <td>0.172000</td>\n",
              "      <td>0.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.500000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>17.500000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>644.000000</td>\n",
              "      <td>0.102000</td>\n",
              "      <td>0.118500</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>0.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>75.250000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.250000</td>\n",
              "      <td>114.250000</td>\n",
              "      <td>917.000000</td>\n",
              "      <td>0.112000</td>\n",
              "      <td>0.157000</td>\n",
              "      <td>0.209000</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>1878.000000</td>\n",
              "      <td>0.143000</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id      radius  ...    symmetry  fractal_dimension\n",
              "count  100.000000  100.000000  ...  100.000000         100.000000\n",
              "mean    50.500000   16.850000  ...    0.193170           0.064690\n",
              "std     29.011492    4.879094  ...    0.030785           0.008151\n",
              "min      1.000000    9.000000  ...    0.135000           0.053000\n",
              "25%     25.750000   12.000000  ...    0.172000           0.059000\n",
              "50%     50.500000   17.000000  ...    0.190000           0.063000\n",
              "75%     75.250000   21.000000  ...    0.209000           0.069000\n",
              "max    100.000000   25.000000  ...    0.304000           0.097000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "bc63d2953223deb5d2a369185f98f1235f5a4489",
        "id": "nShpsSNi3x2R",
        "outputId": "7b677955-674f-40eb-8f7a-281ac45deaed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Cancer.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'diagnosis_result', 'radius', 'texture', 'perimeter', 'area',\n",
              "       'smoothness', 'compactness', 'symmetry', 'fractal_dimension'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnd3tFdvVyk7",
        "outputId": "d962865f-e7b7-4844-d30e-f7c5724dd59c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Cancer.columns.isna()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlvKyECoWQ96",
        "outputId": "ffab0ca5-2842-423c-a8ad-9a4ac71dac43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Cancer.columns.isnull()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7f24b49bec7a5c0498d0d1687951532eb2802928",
        "id": "J_65STOu3x2V",
        "outputId": "0ac420db-eb3b-4b5f-a05c-ae08a1d1436c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "# ID of the patients is unneccessary. So, we drop that!\n",
        "Cancer.drop(labels = ['id'],axis=1, inplace=True)\n",
        "Cancer.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis_result</th>\n",
              "      <th>radius</th>\n",
              "      <th>texture</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>area</th>\n",
              "      <th>smoothness</th>\n",
              "      <th>compactness</th>\n",
              "      <th>symmetry</th>\n",
              "      <th>fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>151</td>\n",
              "      <td>954</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.278</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>133</td>\n",
              "      <td>1326</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>130</td>\n",
              "      <td>1203</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.207</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>78</td>\n",
              "      <td>386</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>135</td>\n",
              "      <td>1297</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.181</td>\n",
              "      <td>0.059</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis_result  radius  texture  ...  compactness  symmetry  fractal_dimension\n",
              "0                M      23       12  ...        0.278     0.242              0.079\n",
              "1                B       9       13  ...        0.079     0.181              0.057\n",
              "2                M      21       27  ...        0.160     0.207              0.060\n",
              "3                M      14       16  ...        0.284     0.260              0.097\n",
              "4                M       9       19  ...        0.133     0.181              0.059\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzIravf__PIk",
        "outputId": "3b04e2cc-7fd7-46ee-a3d0-5bafbdbdde72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "Cancer['diagnosis_result'] = le.fit_transform(Cancer.diagnosis_result)\n",
        "# Malignant Tumors 'M' are encoded as 1 and Beneign Tumors are encoded as 0\n",
        "Cancer.diagnosis_result.value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    62\n",
              "0    38\n",
              "Name: diagnosis_result, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "fea789ad3a09ca6599247903c7e15a2f8e32a253",
        "id": "VyUyJkAC3x2Y",
        "outputId": "9cc2031c-10ca-45e9-b7c8-572d8770bd3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "x = Cancer.iloc[:,1:8]\n",
        "x.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius</th>\n",
              "      <th>texture</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>area</th>\n",
              "      <th>smoothness</th>\n",
              "      <th>compactness</th>\n",
              "      <th>symmetry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>151</td>\n",
              "      <td>954</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.278</td>\n",
              "      <td>0.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>133</td>\n",
              "      <td>1326</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>130</td>\n",
              "      <td>1203</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>78</td>\n",
              "      <td>386</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>135</td>\n",
              "      <td>1297</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius  texture  perimeter  area  smoothness  compactness  symmetry\n",
              "0      23       12        151   954       0.143        0.278     0.242\n",
              "1       9       13        133  1326       0.143        0.079     0.181\n",
              "2      21       27        130  1203       0.125        0.160     0.207\n",
              "3      14       16         78   386       0.070        0.284     0.260\n",
              "4       9       19        135  1297       0.141        0.133     0.181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3d040dc3e591b2a30996e614f709980719506e9e",
        "id": "4OOP063B3x2t",
        "outputId": "0a9692f3-9d94-47f4-aeb6-7ed7e399ab96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# See the Targets\n",
        "y = Cancer.iloc[:, 0]\n",
        "y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    62\n",
              "0    38\n",
              "Name: diagnosis_result, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "732d8ab954f68af7b0d89eec4fa6789dcdd2d8e6",
        "id": "tbiDZvKi3x22"
      },
      "source": [
        "# Normalization: Normalization means all of the values of data, scale between 0 and 1.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "x = scaler.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "63a63a87d3ce57ae5eba95acacca1b5be355b7f2",
        "id": "w9BB22xK3x2-"
      },
      "source": [
        "# We are ready to split data into training and testing.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "#%25 of data will assign as 'Test Data'\n",
        "method_names=[] # In Conclusion part, I'll display the method that gave the best result.\n",
        "method_scores=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "753ff7cdc84f6d495b67a5539f04ea8937e5d780",
        "id": "3-w2NtLS3x3F",
        "outputId": "577c82c1-217a-4e56-cd8e-51cdc2d279cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Let's look at new values.\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75, 7)\n",
            "(25, 7)\n",
            "(75,)\n",
            "(25,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2c4637886423e06e40c77bc00a5b88f027572c1f",
        "id": "K4X1m5CD3x3I"
      },
      "source": [
        "**And now time to classification!**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "949e0fbc546a778ac9fb85ad065457009d38e27c",
        "id": "4NEXQaDJ3x3J",
        "outputId": "3fed0e41-cbf5-48e8-9f13-fbc7e8470e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Firstly, we start with Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(x_train, y_train) #Fitting\n",
        "print(\"Logistic Regression Classification Test Accuracy {}\".format(log_reg.score(x_test,y_test)))\n",
        "method_names.append(\"Logistic Reg.\")\n",
        "method_scores.append(log_reg.score(x_test,y_test))\n",
        "\n",
        "#Confusion Matrix\n",
        "y_pred = log_reg.predict(x_test)\n",
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "#Visualization Confusion Matrix\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Classification Test Accuracy 0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6eb8470d8b5b7e5c44dcc63cd786c326f5be83fc",
        "id": "fmgBFj0h3x3L",
        "outputId": "1dec68d0-8c5e-4543-8789-c4554b617da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Continue with; KNN Classification!\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # 5 is optional.\n",
        "knn.fit(x_train,y_train)\n",
        "print(\"Score for Number of Neighbors = 5: {}\".format(knn.score(x_test,y_test)))\n",
        "method_names.append(\"KNN\")\n",
        "method_scores.append(knn.score(x_test,y_test))\n",
        "\n",
        "#Confusion Matrix\n",
        "y_pred = knn.predict(x_test)\n",
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "#Visualization Confusion Matrix\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for Number of Neighbors = 5: 0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ea5a44d0281f4f34a77c066f0ed12bac885d35cf",
        "id": "Kxd8ZJ7J3x3O",
        "outputId": "af5e3585-9316-4d19-e957-6727805077a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# SVM!\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(x_train,y_train)\n",
        "print(\"SVM Classification Score is: {}\".format(svm.score(x_test,y_test)))\n",
        "method_names.append(\"SVM\")\n",
        "method_scores.append(svm.score(x_test,y_test))\n",
        "\n",
        "#Confusion Matrix\n",
        "y_pred = svm.predict(x_test)\n",
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "#Visualization Confusion Matrix\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Classification Score is: 0.84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "19b6321c1b5a18a045dc4e1636e2b368c082769d",
        "id": "hz9L0krV3x3W",
        "outputId": "32747883-624e-430f-9f2e-9c697a66e61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(x_test,y_test)\n",
        "print(\"Naive Bayes Classification Score: {}\".format(naive_bayes.score(x_test,y_test)))\n",
        "method_names.append(\"Naive Bayes\")\n",
        "method_scores.append(naive_bayes.score(x_test,y_test))\n",
        "\n",
        "#Confusion Matrix\n",
        "y_pred = naive_bayes.predict(x_test)\n",
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "#Visualization Confusion Matrix\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classification Score: 0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "51faaac7300e99421c31e7fd635ee977392caa73",
        "id": "s37_JDQv3x3Z",
        "outputId": "1883a211-2592-4ea2-aa68-29b8cd8e43a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dec_tree = DecisionTreeClassifier()\n",
        "dec_tree.fit(x_train,y_train)\n",
        "print(\"Decision Tree Classification Score: \",dec_tree.score(x_test,y_test))\n",
        "method_names.append(\"Decision Tree\")\n",
        "method_scores.append(dec_tree.score(x_test,y_test))\n",
        "\n",
        "#Confusion Matrix\n",
        "y_pred = dec_tree.predict(x_test)\n",
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "#Visualization Confusion Matrix\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Classification Score:  0.72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4ad7376894ea8ffa78e4765b778993007a387e70",
        "id": "85v7ZHV63x3c",
        "outputId": "daced75b-19b3-4ce8-f31b-6aca38391bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rand_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rand_forest.fit(x_train,y_train)\n",
        "print(\"Random Forest Classification Score: \",rand_forest.score(x_test,y_test))\n",
        "method_names.append(\"Random Forest\")\n",
        "method_scores.append(rand_forest.score(x_test,y_test))\n",
        "\n",
        "#Confusion Matrix\n",
        "y_pred = rand_forest.predict(x_test)\n",
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "#Visualization Confusion Matrix\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Classification Score:  0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d93408822f4b3d162ec6ad75cbaaafbebf663692",
        "id": "LNcKmZyq3x3g",
        "outputId": "91268ca3-f0a1-47bc-de0a-76a30ddaa2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ANN!\n",
        "%%time\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential # initialize neural network library\n",
        "from keras.layers import Dense # build our layers library\n",
        "def build_classifier():\n",
        "    classifier = Sequential() # initialize neural network\n",
        "    classifier.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
        "    classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier, epochs = 200)\n",
        "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "print(\"Accuracy mean: \"+ str(mean))\n",
        "print(\"Accuracy variance: \"+ str(variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5800\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5200\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5200\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5200\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5200\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5200\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5200\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5200\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5200\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5200\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5200\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5200\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5200\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5200\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5200\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5200\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5200\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5200\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5200\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5200\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5200\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5200\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5200\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5400\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5400\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5600\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5800\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5800\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6000\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6200\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.6800\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6800\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6800\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6800\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6800\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6800\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7000\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7000\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.7000\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.7000\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.7000\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7200\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.7400\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7600\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.7600\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7600\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7600\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.8000\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.8000\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.8000\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.8400\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.8400\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.8600\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.8600\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.8600\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8600\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8600\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8600\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8600\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.8600\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.8600\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8800\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8800\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.8800\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8800\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.8800\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8800\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.8800\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8800\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8800\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8800\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8800\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8800\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.8800\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8800\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.8800\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8800\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8800\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.9000\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.9000\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.9000\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.9000\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.9000\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.9000\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.9000\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.9000\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.9000\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.9000\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.9000\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.9000\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.9000\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.9000\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.9000\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.9000\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.9000\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.9000\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.9000\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.9000\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.9000\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.9000\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.9000\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.9000\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.9000\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.9000\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.9000\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.9000\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.9000\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.9000\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.9000\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.9000\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.9000\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.9000\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.9000\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.9000\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.9000\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.9000\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.9000\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.9000\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.9000\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.9000\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.9000\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.9000\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.9000\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.9000\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.9000\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.9000\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.9000\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.9000\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.9000\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.9000\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9000\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.9000\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.9000\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3232 - accuracy: 0.9000\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.9000\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.9000\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3193 - accuracy: 0.9200\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.9200\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.9200\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.9200\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.9200\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.9200\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.9200\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.9200\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.9200\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.9200\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.9200\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3076 - accuracy: 0.9200\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.9200\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.9200\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3051 - accuracy: 0.9200\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.9200\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.9200\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.9200\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.9200\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.9200\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.9200\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.9200\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2969 - accuracy: 0.9200\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.9200\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.9200\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.9200\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.9200\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.9200\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.9200\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.9200\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.9200\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.9200\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.9200\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.9200\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.9200\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.9200\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.9200\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.9200\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.9200\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.9200\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9200\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.9200\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.9200\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.9200\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.9200\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.9200\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.9200\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.9200\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9200\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.9200\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.9200\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9200\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.9200\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9200\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9200\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.9200\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9200\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.9200\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8000\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4800\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.6000\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.6000\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.6000\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.6000\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.6000\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.6000\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.6000\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6000\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.6000\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.6000\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.6000\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.6000\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.6000\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.6000\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.6000\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.6000\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6000\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.6000\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6000\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6000\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.6000\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6806 - accuracy: 0.6000\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.6000\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6000\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.6000\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.6000\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6000\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6000\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6000\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6000\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6000\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6000\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6578 - accuracy: 0.6000\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6000\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6000\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6000\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6000\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6000\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6000\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6000\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6000\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6000\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6000\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6000\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6000\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6000\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6000\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6000\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6000\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.6200\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6200\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6200\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.6200\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6200\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6200\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.6400\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.6600\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.6800\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.6800\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.6800\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7200\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.7200\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7200\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7200\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7200\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7400\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7400\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7600\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7600\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7600\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7800\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8000\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.8200\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8200\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8200\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.8200\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8200\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8200\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8200\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.8200\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8200\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8200\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8200\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8200\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8200\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8400\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8400\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8400\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8600\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8600\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8600\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8600\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8800\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8800\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8800\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8800\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8800\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8800\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8800\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8800\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8800\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8800\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8800\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8800\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8800\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8800\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8800\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.9000\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.9000\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.9000\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.9000\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.9000\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.9000\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8800\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8800\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8800\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8800\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8800\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8800\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8800\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8800\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.9000\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.9000\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.9000\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8800\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8800\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8800\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.9000\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.9000\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.9000\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3138 - accuracy: 0.9000\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3120 - accuracy: 0.9000\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.9000\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.9000\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.9000\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.9000\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3026 - accuracy: 0.9000\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9000\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.9000\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.9000\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.9000\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2940 - accuracy: 0.9000\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.9000\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9000\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.9000\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.9000\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.9000\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2851 - accuracy: 0.9000\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9000\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.9000\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.9000\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.9000\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.9000\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.9000\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9000\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9000\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.9000\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9000\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9000\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.9000\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9000\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9000\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9000\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.9000\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9000\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9000\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9000\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9000\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.9000\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9000\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9000\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9000\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9000\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9000\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.9000\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9000\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.9000\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9000\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.9200\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9200\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2434 - accuracy: 0.9200\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9200\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.9000\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9000\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9000\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9000\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9000\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9000\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9000\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9000\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9000\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2314 - accuracy: 0.9200\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2307 - accuracy: 0.9200\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2294 - accuracy: 0.9200\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9000\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9000\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9000\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdfd7c97ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8400\n",
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.6400\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6400\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.6400\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.6400\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.6400\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6400\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.6400\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.6400\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.6400\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.6400\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.6400\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6400\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6400\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6400\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.6400\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.6400\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.6400\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.6400\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6400\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.6400\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6803 - accuracy: 0.6400\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.6400\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.6400\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.6400\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6400\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6400\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6400\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6400\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6400\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6400\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6400\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6400\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6400\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6400\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6400\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6400\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6400\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6400\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6400\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6400\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6400\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6400\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6400\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6400\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6400\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6400\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6400\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6400\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6400\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6400\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6400\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.5957 - accuracy: 0.6400\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6400\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6400\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6400\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6400\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5769 - accuracy: 0.6400\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.6600\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.6600\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.6600\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5604 - accuracy: 0.6600\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.6600\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.6600\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.6800\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.6800\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.6800\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.6800\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.6800\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7000\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7000\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.7200\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7200\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7200\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7600\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7800\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.8000\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.8000\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.8000\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.8000\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8000\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8000\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8000\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8000\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.8200\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8400\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8400\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8600\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8600\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8600\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8400\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8400\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8400\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8400\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8400\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8400\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8400\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8400\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8400\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8400\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8400\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8400\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3899 - accuracy: 0.8400\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8400\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8600\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8800\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8800\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8800\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8800\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8800\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8800\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8800\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8800\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8800\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3628 - accuracy: 0.8800\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3616 - accuracy: 0.8800\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3600 - accuracy: 0.8800\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8800\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8800\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8800\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8800\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8800\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8800\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8800\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8800\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8800\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8800\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8800\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8800\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8800\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3439 - accuracy: 0.8800\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8800\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3421 - accuracy: 0.8800\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8800\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8800\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8800\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8800\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8800\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8800\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8800\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8800\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8800\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8800\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8800\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8800\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8800\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.8800\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3331 - accuracy: 0.8800\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8800\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8800\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8800\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8800\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8800\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8800\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8800\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8800\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8800\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8800\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8800\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8800\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8800\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8800\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8800\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8800\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8800\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8800\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8800\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8800\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8800\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8800\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8800\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8800\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8800\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8800\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8800\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8800\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8800\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8800\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3208 - accuracy: 0.8800\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8800\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8800\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8800\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8800\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8800\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8800\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8800\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8800\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8800\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8800\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8800\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8800\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8800\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8800\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8800\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8800\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8800\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8800\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8800\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3150 - accuracy: 0.8800\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8800\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdfd6bb1488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.9200\n",
            "Accuracy mean: 0.8533333341280619\n",
            "Accuracy variance: 0.04988877067939322\n",
            "CPU times: user 7.43 s, sys: 595 ms, total: 8.02 s\n",
            "Wall time: 11 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b708053280ccbc39ca8dd9f8a52aebb4355c0d19",
        "id": "vpvcXvyj3x3n"
      },
      "source": [
        "method_names.append(\"ANN\")\n",
        "method_scores.append(0.853))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9a68eec281f6f88ff2548e94935305d9d904b47a",
        "id": "q7dXume23x3r",
        "outputId": "85e76c1f-706f-49c6-a9b8-e86141c39b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "trainX = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))\n",
        "testX = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
        "# Print and check shapes\n",
        "print(\"Shape of trainX is {}\".format(trainX.shape))\n",
        "print(\"Shape of testX is {}\".format(testX.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of trainX is (75, 7, 1)\n",
            "Shape of testX is (25, 7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "bd120115b813ce73a5667d7dbe3123965e799cf4",
        "id": "r2VRSF2U3x3u",
        "outputId": "585c1dd3-03ba-4d8a-cb70-014b9cef467a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Dense, SimpleRNN, Dropout\n",
        "from keras.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "# Add the first layer and Dropout regularization\n",
        "model.add(SimpleRNN(units=100,activation='tanh',return_sequences=True, \n",
        "                    input_shape=(trainX.shape[1],1)))\n",
        "model.add(Dropout(0.20))\n",
        "# Second layer and Dropout regularization\n",
        "model.add(SimpleRNN(units = 100, activation='tanh',return_sequences=True))\n",
        "model.add(Dropout(0.20))\n",
        "# Third layer and Dropout regularization\n",
        "model.add(SimpleRNN(units = 70, activation='tanh', return_sequences= True))\n",
        "model.add(Dropout(0.20))\n",
        "# Fourth layer and Dropout regularization\n",
        "model.add(SimpleRNN(units = 50))\n",
        "model.add(Dropout(0.20))\n",
        "# Add final or output layer\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile our RNN model\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['accuracy'])\n",
        "# Fitting the RNN to the training set\n",
        "model.fit(trainX, y_train, epochs = 200, batch_size=32)\n",
        "# Remember; epochs, batch_size etc. are just some of hyper parameters. \n",
        "# You can change these parameters whatever you want\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "print(\"Accuracy mean: \"+ str(mean))\n",
        "print(\"Accuracy variance: \"+ str(variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.8700 - accuracy: 0.6133\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6159 - accuracy: 0.5733\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6600 - accuracy: 0.6267\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8497 - accuracy: 0.5333\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.5200\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5320 - accuracy: 0.7200\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.6533\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7600\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6482 - accuracy: 0.6400\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6928 - accuracy: 0.5200\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.6133\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5894 - accuracy: 0.6133\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6629 - accuracy: 0.5600\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.4525 - accuracy: 0.6000\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.6000\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.6667\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.4068 - accuracy: 0.6667\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.5867\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4553 - accuracy: 0.6267\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.6933\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.6267\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.6400\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.6533\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.7333\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.5641 - accuracy: 0.6400\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2588 - accuracy: 0.7867\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.6533\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.6800\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2867 - accuracy: 0.7733\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.6933\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.7200\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3293 - accuracy: 0.7200\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.6533\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2447 - accuracy: 0.7600\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.5733\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.6267\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.6800\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.6800\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2888 - accuracy: 0.7867\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2622 - accuracy: 0.7600\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2825 - accuracy: 0.6800\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3387 - accuracy: 0.6267\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.6400\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2848 - accuracy: 0.8000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3369 - accuracy: 0.6800\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2484 - accuracy: 0.8000\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3371 - accuracy: 0.5733\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2917 - accuracy: 0.6533\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.6533\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.3406 - accuracy: 0.6933\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.6933\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.6800\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.7333\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2414 - accuracy: 0.7467\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2473 - accuracy: 0.6933\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3068 - accuracy: 0.7067\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.7200\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.6933\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.3100 - accuracy: 0.7333\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2874 - accuracy: 0.7600\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2742 - accuracy: 0.6400\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.6933\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.7067\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2896 - accuracy: 0.6800\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.7600\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2217 - accuracy: 0.7467\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.7600\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2584 - accuracy: 0.7200\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2109 - accuracy: 0.7067\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2184 - accuracy: 0.6800\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2929 - accuracy: 0.6667\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1652 - accuracy: 0.8000\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2433 - accuracy: 0.7733\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2257 - accuracy: 0.7600\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1974 - accuracy: 0.7867\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.7333\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.7467\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1792 - accuracy: 0.7600\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2148 - accuracy: 0.7600\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.2213 - accuracy: 0.7467\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1851 - accuracy: 0.7733\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.8267\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2065 - accuracy: 0.7200\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.8400\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1692 - accuracy: 0.8000\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1867 - accuracy: 0.7867\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2174 - accuracy: 0.7333\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2250 - accuracy: 0.7733\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1575 - accuracy: 0.7733\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.7333\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2223 - accuracy: 0.7333\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1832 - accuracy: 0.8000\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2064 - accuracy: 0.7600\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2076 - accuracy: 0.7467\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.7067\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2366 - accuracy: 0.6933\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1807 - accuracy: 0.7067\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.8000\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2207 - accuracy: 0.8133\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.7867\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2095 - accuracy: 0.8133\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.8133\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2196 - accuracy: 0.7733\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2111 - accuracy: 0.7733\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2074 - accuracy: 0.7333\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1877 - accuracy: 0.7467\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2050 - accuracy: 0.7467\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.2018 - accuracy: 0.7600\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1236 - accuracy: 0.8533\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2101 - accuracy: 0.7867\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.8267\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2521 - accuracy: 0.7600\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1925 - accuracy: 0.7867\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2184 - accuracy: 0.6667\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1824 - accuracy: 0.7733\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2015 - accuracy: 0.7733\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1735 - accuracy: 0.7867\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1945 - accuracy: 0.7600\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2002 - accuracy: 0.7733\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1580 - accuracy: 0.8133\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1613 - accuracy: 0.8000\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1891 - accuracy: 0.7067\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.8533\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.8933\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1871 - accuracy: 0.7733\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.7867\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1468 - accuracy: 0.8267\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1545 - accuracy: 0.8133\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1597 - accuracy: 0.8267\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.8000\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1904 - accuracy: 0.7467\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.8533\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.8267\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.8533\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1579 - accuracy: 0.8400\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1611 - accuracy: 0.8400\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1429 - accuracy: 0.8400\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1852 - accuracy: 0.7333\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1733 - accuracy: 0.7733\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.7867\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.8133\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1385 - accuracy: 0.8267\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.8000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1139 - accuracy: 0.8533\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.8133\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1777 - accuracy: 0.8133\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1634 - accuracy: 0.8133\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1313 - accuracy: 0.8800\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1697 - accuracy: 0.7867\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1937 - accuracy: 0.7067\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1601 - accuracy: 0.8400\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.8800\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1380 - accuracy: 0.8533\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1914 - accuracy: 0.7467\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1569 - accuracy: 0.7867\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1663 - accuracy: 0.8000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.8133\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1268 - accuracy: 0.8400\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1281 - accuracy: 0.8400\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 0.8533\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.8533\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.8400\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.8000\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1296 - accuracy: 0.8400\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1409 - accuracy: 0.8267\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.8267\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1597 - accuracy: 0.7867\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.7867\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1564 - accuracy: 0.8400\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.8400\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1730 - accuracy: 0.8000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.8000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1772 - accuracy: 0.7867\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1345 - accuracy: 0.8267\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1465 - accuracy: 0.7867\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1238 - accuracy: 0.8667\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.8400\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.8000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.8533\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1676 - accuracy: 0.8533\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1273 - accuracy: 0.8667\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1304 - accuracy: 0.8667\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1323 - accuracy: 0.8400\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1671 - accuracy: 0.7867\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.1293 - accuracy: 0.8267\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.7733\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.8533\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1444 - accuracy: 0.8133\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.8133\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.7600\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.8267\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1174 - accuracy: 0.8533\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1098 - accuracy: 0.9067\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1289 - accuracy: 0.8533\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 0.8400\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.8267\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.8667\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1481 - accuracy: 0.8000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.1111 - accuracy: 0.8933\n",
            "Accuracy mean: 0.8533333341280619\n",
            "Accuracy variance: 0.04988877067939322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6b90913a8a1a728d6f6d500ac683417af7b6a370",
        "id": "m_hfsZkc3x3y"
      },
      "source": [
        "method_names.append(\"RNN\")\n",
        "method_scores.append(0.8533)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "89fae4f677c7d6638e95f040fea61aae7e3493f8",
        "id": "ziYv_82f3x33"
      },
      "source": [
        "**CONCLUSION**\n",
        "\n",
        "We've already completed to train our data with a lot of different method. Let's look which method is given the best result to us!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "af35e768076f7018e68d2d191ffb12e64d7fef06",
        "id": "HBhCSSC33x34",
        "outputId": "63c373f7-9381-45cc-80a0-6c029a3f9e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.ylim([0.60,1])\n",
        "plt.bar(method_names,method_scores,width=0.5)\n",
        "plt.xlabel('Method Name')\n",
        "plt.ylabel('Method Score')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Method Score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}